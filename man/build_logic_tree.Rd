% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/build_logic_tree.R
\name{build_logic_tree}
\alias{build_logic_tree}
\title{Build Logic Tree for Optimizing F1 Score}
\usage{
build_logic_tree(
  data,
  outcome,
  columns,
  max_depth = 3,
  current_depth = 1,
  parent_score = 0,
  previous_rule = NULL,
  previous_rule_name = "",
  best_info_env,
  max_trees = 5
)
}
\arguments{
\item{data}{A data frame containing the features and the outcome variable.}

\item{outcome}{A character string specifying the name of the outcome variable.}

\item{columns}{A character vector of feature names to be considered for splitting.}

\item{max_depth}{An integer specifying the maximum depth of the tree. Default is 3.}

\item{current_depth}{An integer specifying the current depth of the tree. Default is 1.}

\item{path_f1}{A numeric value representing the F1 score of the current path. Default is 0.}

\item{path_weight}{A numeric value representing the weight of the current path (number of observations). Default is 0.}
}
\value{
A list representing the tree structure with splits, F1 scores, and path F1 scores.
}
\description{
This function builds a decision tree by recursively finding the best splits to optimize the F1 score.
It searches for logical interactions (AND and OR statements) among the features,
and calculates a weighted F1 score along the paths of the tree.
}
\examples{
# Assuming 'df' is your data frame and 'AGO_PR' is your outcome variable
columns <- colnames(df)[grep("^KRFP", colnames(df))]
tree <- build_logic_tree(df, "AGO_PR", columns, max_depth = 3)
print(tree)
}
