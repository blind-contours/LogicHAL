data[[outcome]] <- recode(data[[outcome]], `inact.` = 0, `act.` = 1, `w.act.` = 1, `inc.` = 0)
# Ensure the outcome column is numeric
data[[outcome]] <- as.numeric(data[[outcome]])
# Identify the KRFP columns
krfp_columns <- grep("^KRFP", colnames(data), value = TRUE)
# Filter KRFP columns based on the minimum number of indicators
min_n_indicator <- 100
filtered_krfp_columns <- krfp_columns[sapply(data[krfp_columns], function(x) sum(x) >= min_n_indicator)]
# Create the filtered dataframe
filtered_data <- data %>%
select(-one_of(krfp_columns)) %>%
bind_cols(data[filtered_krfp_columns])
# Split the data into training and testing sets
train_index <- createDataPartition(filtered_data[[outcome]], p = 0.7, list = FALSE)
filtered_data[[outcome]]
table(filtered_data[[outcome]])
# Split the data into training and testing sets
train_index <- createDataPartition(filtered_data[[outcome]], p = 0.7, list = FALSE)
train_data <- filtered_data[train_index, ]
test_data <- filtered_data[-train_index, ]
# Run LogicHAL on the training data
logic_result <- LogicHAL(data = train_data, outcome = outcome, columns = filtered_krfp_columns, max_trees = 20,
max_operators = 4, family = "binomial", num_cores = 7, max_iterations = 40,
no_improvement_threshold = 5, beam_width = 2)
load_all()
install()
# Run LogicHAL on the training data
logic_result <- LogicHAL(data = train_data, outcome = outcome, columns = filtered_krfp_columns, max_trees = 20,
max_operators = 4, family = "binomial", num_cores = 7, max_iterations = 40,
no_improvement_threshold = 5, beam_width = 2)
document()
load_all()
install()
# Run LogicHAL on the training data
logic_result <- LogicHAL(data = train_data, outcome = outcome, columns = filtered_krfp_columns, max_trees = 20,
max_operators = 4, family = "binomial", num_cores = 7, max_iterations = 40,
no_improvement_threshold = 5, beam_width = 2)
# Calculate the number of iterations per core
iterations_per_core <- ceiling(max_iterations / num_cores)
load_all()
load_all()
install()
# Run LogicHAL on the training data
logic_result <- LogicHAL(data = train_data, outcome = outcome, columns = filtered_krfp_columns, max_trees = 20,
max_operators = 4, family = "binomial", num_cores = 10, max_iterations = 40,
no_improvement_threshold = 5, beam_width = 1)
data = train_data
columns = filtered_krfp_columns
max_trees = 20
max_operators = 4
family = "binomial"
num_cores = 10
max_iterations = 40
no_improvement_threshold = 5
beam_width = 1
max_temperature = 1
min_temperature = 0.001
# Helper function to fit Lasso
fit_lasso <- function(features, outcome, family) {
model <- cv.glmnet(as.matrix(features), outcome, family = family, alpha = 1)
return(model)
}
# Helper function to check if a column is binary
is_binary_column <- function(column) {
unique_values <- unique(column)
return(length(unique_values) == 2 && all(unique_values %in% c(0, 1)))
}
# Identify non-binary columns
non_binary_columns <- columns[!sapply(data[columns], is_binary_column)]
if (length(non_binary_columns) > 0) {
# Create basis functions for non-binary columns
basis_functions <- create_basis_functions(data, non_binary_columns, num_knots)
basis_function_names <- colnames(basis_functions)
# Replace non-binary columns in the original data
data <- cbind(data, basis_functions)
columns <- c(setdiff(columns, non_binary_columns), basis_function_names)
}
# Start the timer and run the function
time_taken_pairs <- system.time({
two_way_logic_roots <- compute_pairwise_logic_interactions_parallel(data, columns, outcome, num_cores = num_cores)
})
elapsed_time_pairs <- time_taken_pairs["elapsed"]
elapsed_time_pairs
time_taken_pairs
length(two_way_logic_roots$F1And)
cl <- makeCluster(num_cores)
# Ensure necessary packages are loaded on each worker
clusterEvalQ(cl, {
library(dplyr)
library(magrittr)
library(Rcpp)
library(LogicHAL)
})
# Calculate the number of iterations per core
iterations_per_core <- ceiling(max_iterations / num_cores)
# Evaluate function parameters
data <- data
outcome <- outcome
columns <- columns
max_operators <- max_operators
max_trees <- max_trees
max_temperature <- max_temperature
min_temperature <- min_temperature
max_iterations <- max_iterations
no_improvement_threshold <- no_improvement_threshold
beam_width <- beam_width
# Export objects to the cluster
clusterExport(cl, c("data", "outcome", "columns", "max_trees", "max_operators",
"max_temperature", "min_temperature", "iterations_per_core",
"no_improvement_threshold", "two_way_logic_roots", "beam_width" ), envir = environment())
iterations_per_core
max_iterations = iterations_per_core
max_iterations
best_info_env <- new.env()
best_info_env$best_scores <- rep(-Inf, max_trees)
best_info_env$best_rule_paths <- vector("list", max_trees)
best_info_env$best_complexities <- rep(Inf, max_trees)
total_iterations <- 0
iteration_counter <- 0
no_improvement_counter <- 0
previous_best_info <- list(scores = best_info_env$best_scores, paths = best_info_env$best_rule_paths)
beam_width
load_all()
best_info_env <- new.env()
best_info_env$best_scores <- rep(-Inf, max_trees)
best_info_env$best_rule_paths <- vector("list", max_trees)
best_info_env$best_complexities <- rep(Inf, max_trees)
total_iterations <- 0
iteration_counter <- 0
no_improvement_counter <- 0
previous_best_info <- list(scores = best_info_env$best_scores, paths = best_info_env$best_rule_paths)
external_temperature <- cooling_schedule(total_iterations, max_iterations, max_temperature, min_temperature)
iteration_time <- system.time({
result <- recursive_build_logic_tree(data, outcome, columns, max_operators, current_operators = 1, parent_score = 0, previous_rule = NULL, previous_rule_name = "", best_info_env = best_info_env, external_temperature, two_way_logic_roots, beam_width)
})
iteration_time
result
best_info_env$best_scores
best_info_env$best_rule_paths
max_iterations
best_info_env <- new.env()
best_info_env$best_scores <- rep(-Inf, max_trees)
best_info_env$best_rule_paths <- vector("list", max_trees)
best_info_env$best_complexities <- rep(Inf, max_trees)
total_iterations <- 0
iteration_counter <- 0
no_improvement_counter <- 0
previous_best_info <- list(scores = best_info_env$best_scores, paths = best_info_env$best_rule_paths)
while (total_iterations < max_iterations && no_improvement_counter < no_improvement_threshold) {
external_temperature <- cooling_schedule(total_iterations, max_iterations, max_temperature, min_temperature)
iteration_time <- system.time({
result <- recursive_build_logic_tree(data, outcome, columns, max_operators, current_operators = 1, parent_score = 0, previous_rule = NULL, previous_rule_name = "", best_info_env = best_info_env, external_temperature, two_way_logic_roots, beam_width)
})
total_iterations <- total_iterations + 1
iteration_counter <- iteration_counter + 1
# Check for improvement
if (!identical(previous_best_info$scores, best_info_env$best_scores)) {
no_improvement_counter <- 0
previous_best_info$scores <- best_info_env$best_scores
} else {
no_improvement_counter <- no_improvement_counter + 1
}
}
best_info_env$best_scores
best_info_env$best_rule_paths
max_trees
best_info_env <- new.env()
best_info_env$best_scores <- rep(-Inf, max_trees)
best_info_env$best_rule_paths <- vector("list", max_trees)
best_info_env$best_complexities <- rep(Inf, max_trees)
total_iterations <- 0
iteration_counter <- 0
no_improvement_counter <- 0
previous_best_info <- list(scores = best_info_env$best_scores, paths = best_info_env$best_rule_paths)
debugonce(recursive_build_logic_tree)
total_iterations <- 0
iteration_counter <- 0
no_improvement_counter <- 0
previous_best_info <- list(scores = best_info_env$best_scores, paths = best_info_env$best_rule_paths)
while (total_iterations < max_iterations && no_improvement_counter < no_improvement_threshold) {
external_temperature <- cooling_schedule(total_iterations, max_iterations, max_temperature, min_temperature)
iteration_time <- system.time({
result <- recursive_build_logic_tree(data, outcome, columns, max_operators, current_operators = 1, parent_score = 0, previous_rule = NULL, previous_rule_name = "", best_info_env = best_info_env, external_temperature, two_way_logic_roots, beam_width)
})
total_iterations <- total_iterations + 1
iteration_counter <- iteration_counter + 1
# Check for improvement
if (!identical(previous_best_info$scores, best_info_env$best_scores)) {
no_improvement_counter <- 0
previous_best_info$scores <- best_info_env$best_scores
} else {
no_improvement_counter <- no_improvement_counter + 1
}
}
best_info_env$best_complexities
best_info_env$best_scores
best_info_env$best_rule_paths
1:min(nrow(comparison_df), max_trees)
max_trees
# Evaluate function parameters
data <- data
outcome <- outcome
columns <- columns
max_operators <- max_operators
max_trees <- max_trees
max_temperature <- max_temperature
min_temperature <- min_temperature
max_iterations <- max_iterations
no_improvement_threshold <- no_improvement_threshold
beam_width <- beam_width
best_info_env <- new.env()
best_info_env$best_scores <- rep(-Inf, max_trees)
best_info_env$best_rule_paths <- vector("list", max_trees)
best_info_env$best_complexities <- rep(Inf, max_trees)
total_iterations <- 0
iteration_counter <- 0
no_improvement_counter <- 0
previous_best_info <- list(scores = best_info_env$best_scores, paths = best_info_env$best_rule_paths)
external_temperature <- cooling_schedule(total_iterations, max_iterations, max_temperature, min_temperature)
iteration_time <- system.time({
result <- recursive_build_logic_tree(data, outcome, columns, max_operators, current_operators = 1, parent_score = 0, previous_rule = NULL, previous_rule_name = "", best_info_env = best_info_env, external_temperature, two_way_logic_roots, beam_width)
})
previous_best_info$scores
best_info_env$best_scores
best_info_env$best_rule_paths
max_operators
load_all()
install()
num_cores
# Calculate the number of iterations per core
iterations_per_core <- ceiling(max_iterations / num_cores)
# Evaluate function parameters
data <- data
outcome <- outcome
columns <- columns
max_operators <- max_operators
max_trees <- max_trees
max_temperature <- max_temperature
min_temperature <- min_temperature
max_iterations <- max_iterations
no_improvement_threshold <- no_improvement_threshold
beam_width <- beam_width
# Export objects to the cluster
clusterExport(cl, c("data", "outcome", "columns", "max_trees", "max_operators",
"max_temperature", "min_temperature", "iterations_per_core",
"no_improvement_threshold", "two_way_logic_roots", "beam_width" ), envir = environment())
results <- parLapply(cl, 1:num_cores, function(x) {
run_single_iteration(data, outcome, columns, max_operators, max_trees, max_temperature, min_temperature, max_iterations = iterations_per_core, two_way_logic_roots, beam_width, max_trees)
})
# Load necessary libraries
library(dplyr)
library(glmnet)
library(Rcpp)
library(LogicHAL)
library(randomForest)
library(caret)
library(LogicReg)
set.seed(42)
# Load the dataframe
file_path <- "//Users/davidmccoy/Downloads/Nura_database_merged_fingerprints.csv"
df <- read.csv(file_path, stringsAsFactors = FALSE)
# Replace 'n.a.' with NA in all relevant columns
outcome_columns <- c("ANT_PR", "BIN_PR", "AGO_PXR", "ANT_PXR", "BIN_PXR", "AGO_RXR", "ANT_RXR", "BIN_RXR",
"AGO_GR", "ANT_GR", "BIN_GR", "AGO_AR", "ANT_AR", "BIN_AR", "AGO_ERA", "ANT_ERA",
"BIN_ERA", "AGO_ERB", "ANT_ERB", "BIN_ERB", "AGO_FXR", "ANT_FXR", "BIN_FXR", "AGO_PPARD",
"ANT_PPARD", "BIN_PPARD", "AGO_PPARG", "ANT_PPARG", "BIN_PPARG", "AGO_PPARA", "ANT_PPARA", "BIN_PPARA")
df[outcome_columns] <- lapply(df[outcome_columns], function(x) replace(x, x == "n.a.", NA))
# Initialize an empty list to store results
results <- list()
# Function to process each outcome
process_outcome <- function(outcome) {
# Remove rows where outcome is NA
data <- df[!is.na(df[[outcome]]), ]
# Replace specific values in the outcome column
data[[outcome]] <- recode(data[[outcome]], `inact.` = 0, `act.` = 1, `w.act.` = 1, `inc.` = 0)
# Ensure the outcome column is numeric
data[[outcome]] <- as.numeric(data[[outcome]])
# Identify the KRFP columns
krfp_columns <- grep("^KRFP", colnames(data), value = TRUE)
# Filter KRFP columns based on the minimum number of indicators
min_n_indicator <- 100
filtered_krfp_columns <- krfp_columns[sapply(data[krfp_columns], function(x) sum(x) >= min_n_indicator)]
# Create the filtered dataframe
filtered_data <- data %>%
select(-one_of(krfp_columns)) %>%
bind_cols(data[filtered_krfp_columns])
# Split the data into training and testing sets
train_index <- createDataPartition(filtered_data[[outcome]], p = 0.7, list = FALSE)
train_data <- filtered_data[train_index, ]
test_data <- filtered_data[-train_index, ]
# Run LogicHAL on the training data
logic_result <- LogicHAL(data = train_data, outcome = outcome, columns = filtered_krfp_columns, max_trees = 20,
max_operators = 4, family = "binomial", num_cores = 10, max_iterations = 40,
no_improvement_threshold = 5, beam_width = 1)
# Logistic regression with logic regression
logreg_results <- logreg(resp = train_data[[outcome]] , bin = train_data[filtered_krfp_columns], select = 2, nleaves = 3)
logreg_predictions_test <- predict(logreg_results, newbin = test_data[, c(filtered_krfp_columns)])
logreg_predictions_train <- predict(logreg_results, newbin = train_data[, c(filtered_krfp_columns)])
logreg_predictions_test <- ifelse(logreg_predictions_test > 0.5, 1, 0)
logreg_predictions_train <- ifelse(logreg_predictions_train > 0.5, 1, 0)
logreg_conf_matrix <- confusionMatrix(as.factor(logreg_predictions_test), as.factor(test_data[[outcome]]))
logreg_accuracy <- logreg_conf_matrix$overall['Accuracy']
# Train a Random Forest model on the training data
rf_model <- randomForest(as.factor(get(outcome)) ~ ., data = train_data[, c(filtered_krfp_columns, outcome)], importance = TRUE)
# Predict outcomes on the test set using Random Forest
rf_predictions <- predict(rf_model, newdata = test_data[, c(filtered_krfp_columns, outcome)])
# Evaluate Random Forest model performance
rf_conf_matrix <- confusionMatrix(as.factor(rf_predictions), as.factor(test_data[[outcome]]))
rf_accuracy <- rf_conf_matrix$overall['Accuracy']
# Evaluate LogicHAL rules on the test set
evaluate_logic_rules <- function(rules, data) {
features <- sapply(rules, function(rule) {
as.numeric(eval(parse(text = rule), envir = data))
})
features <- as.matrix(features)
colnames(features) <- rules
return(features)
}
logic_features_test <- evaluate_logic_rules(logic_result$trees, test_data)
logic_features_train <- evaluate_logic_rules(logic_result$trees, train_data)
# Predict outcomes on the test set using LogicHAL
logic_predictions_test <- predict(logic_result$model, logic_features_test, type = "response")
logic_predictions_train <- predict(logic_result$model, logic_features_train, type = "response")
logic_predictions <- ifelse(logic_predictions_test > 0.3, 1, 0)
# Evaluate LogicHAL model performance
logic_conf_matrix <- confusionMatrix(as.factor(as.vector(logic_predictions)), as.factor(test_data[[outcome]]))
logic_accuracy <- logic_conf_matrix$overall['Accuracy']
# Return the results
list(
outcome = outcome,
rf_accuracy = rf_accuracy,
logic_accuracy = logic_accuracy,
logreg_accuracy = logreg_accuracy,
logic_rules = logic_result$trees
)
}
outcome_columns
outcome <- "ANT_PR"
# Remove rows where outcome is NA
data <- df[!is.na(df[[outcome]]), ]
# Replace specific values in the outcome column
data[[outcome]] <- recode(data[[outcome]], `inact.` = 0, `act.` = 1, `w.act.` = 1, `inc.` = 0)
# Ensure the outcome column is numeric
data[[outcome]] <- as.numeric(data[[outcome]])
# Identify the KRFP columns
krfp_columns <- grep("^KRFP", colnames(data), value = TRUE)
# Filter KRFP columns based on the minimum number of indicators
min_n_indicator <- 100
filtered_krfp_columns <- krfp_columns[sapply(data[krfp_columns], function(x) sum(x) >= min_n_indicator)]
# Create the filtered dataframe
filtered_data <- data %>%
select(-one_of(krfp_columns)) %>%
bind_cols(data[filtered_krfp_columns])
# Split the data into training and testing sets
train_index <- createDataPartition(filtered_data[[outcome]], p = 0.7, list = FALSE)
train_data <- filtered_data[train_index, ]
test_data <- filtered_data[-train_index, ]
data = train_data
columns = filtered_krfp_columns
max_trees = 20
max_operators = 4
family = "binomial"
num_cores = 10
max_iterations = 40
no_improvement_threshold = 5
beam_width = 1
max_temperature = 1
min_temperature = 0.001
max_iterations
no_improvement_threshold
beam_width
num_cores = detectCores() - 1
library(parallel)
num_cores = detectCores() - 1
# Helper function to fit Lasso
fit_lasso <- function(features, outcome, family) {
model <- cv.glmnet(as.matrix(features), outcome, family = family, alpha = 1)
return(model)
}
# Helper function to check if a column is binary
is_binary_column <- function(column) {
unique_values <- unique(column)
return(length(unique_values) == 2 && all(unique_values %in% c(0, 1)))
}
# Identify non-binary columns
non_binary_columns <- columns[!sapply(data[columns], is_binary_column)]
if (length(non_binary_columns) > 0) {
# Create basis functions for non-binary columns
basis_functions <- create_basis_functions(data, non_binary_columns, num_knots)
basis_function_names <- colnames(basis_functions)
# Replace non-binary columns in the original data
data <- cbind(data, basis_functions)
columns <- c(setdiff(columns, non_binary_columns), basis_function_names)
}
# Start the timer and run the function
time_taken_pairs <- system.time({
two_way_logic_roots <- compute_pairwise_logic_interactions_parallel(data, columns, outcome, num_cores = num_cores)
})
elapsed_time_pairs <- time_taken_pairs["elapsed"]
cl <- makeCluster(num_cores)
# Ensure necessary packages are loaded on each worker
clusterEvalQ(cl, {
library(dplyr)
library(magrittr)
library(Rcpp)
library(LogicHAL)
})
# Calculate the number of iterations per core
iterations_per_core <- ceiling(max_iterations / num_cores)
# Evaluate function parameters
data <- data
outcome <- outcome
columns <- columns
max_operators <- max_operators
max_trees <- max_trees
max_temperature <- max_temperature
min_temperature <- min_temperature
max_iterations <- max_iterations
no_improvement_threshold <- no_improvement_threshold
beam_width <- beam_width
# Export objects to the cluster
clusterExport(cl, c("data", "outcome", "columns", "max_trees", "max_operators",
"max_temperature", "min_temperature", "iterations_per_core",
"no_improvement_threshold", "two_way_logic_roots", "beam_width" ), envir = environment())
results <- parLapply(cl, 1:num_cores, function(x) {
run_single_iteration(data, outcome, columns, max_operators, max_trees, max_temperature, min_temperature, max_iterations = iterations_per_core, two_way_logic_roots, beam_width, max_trees)
})
max_trees
max_trees <- max_trees
max_temperature <- max_temperature
min_temperature <- min_temperature
max_iterations <- max_iterations
no_improvement_threshold <- no_improvement_threshold
beam_width <- beam_width
# Export objects to the cluster
clusterExport(cl, c("data", "outcome", "columns", "max_trees", "max_operators",
"max_temperature", "min_temperature", "iterations_per_core",
"no_improvement_threshold", "two_way_logic_roots", "beam_width" ), envir = environment())
results <- parLapply(cl, 1:num_cores, function(x) {
run_single_iteration(data, outcome, columns, max_operators, max_trees, max_temperature, min_temperature, max_iterations = iterations_per_core, two_way_logic_roots, beam_width, max_trees)
})
document()
library(devtools)
document()
load_all()
install()
# Export objects to the cluster
clusterExport(cl, c("data", "outcome", "columns", "max_trees", "max_operators",
"max_temperature", "min_temperature", "iterations_per_core",
"no_improvement_threshold", "two_way_logic_roots", "beam_width" ), envir = environment())
results <- parLapply(cl, 1:num_cores, function(x) {
run_single_iteration(data, outcome, columns, max_operators, max_trees, max_temperature, min_temperature, max_iterations = iterations_per_core, two_way_logic_roots, beam_width, max_trees)
})
run_single_iteration(data, outcome, columns, max_operators, max_trees = max_trees, max_temperature, min_temperature, max_iterations = iterations_per_core, two_way_logic_roots, beam_width, max_trees)
debugonce(run_single_iteration)
run_single_iteration(data, outcome, columns, max_operators, max_trees = max_trees, max_temperature, min_temperature, max_iterations = iterations_per_core, two_way_logic_roots, beam_width, max_trees)
load_all()
# Export objects to the cluster
clusterExport(cl, c("data", "outcome", "columns", "max_trees", "max_operators",
"max_temperature", "min_temperature", "iterations_per_core",
"no_improvement_threshold", "two_way_logic_roots", "beam_width" ), envir = environment())
results <- parLapply(cl, 1:num_cores, function(x) {
run_single_iteration(data, outcome, columns, max_operators, max_trees = max_trees, max_temperature, min_temperature, max_iterations = iterations_per_core, two_way_logic_roots, beam_width, max_trees)
})
#' @param min_temperature Numeric. The minimum temperature in the middle of the iterations.
#' @param max_iterations Integer. The maximum number of iterations to run the logic tree building process.
#'
#' @return List. A list containing the best scores and best rule paths found during the iteration.
#'
#' @examples
#' data <- data.frame(x1 = rnorm(100), x2 = rnorm(100), y = sample(0:1, 100, replace = TRUE))
#' run_single_iteration(data, outcome = "y", columns = c("x1", "x2"), max_operators = 3, initial_temperature = 1, min_temperature = 0.01, max_iterations = 100)
#'
#' @export
run_single_iteration <- function(data, outcome, columns, max_operators, max_trees, max_temperature, min_temperature, max_iterations, two_way_logic_roots, three_way_logic_roots, beam_width) {
best_info_env <- new.env()
best_info_env$best_scores <- rep(-Inf, max_trees)
best_info_env$best_rule_paths <- vector("list", max_trees)
best_info_env$best_complexities <- rep(Inf, max_trees)
total_iterations <- 0
iteration_counter <- 0
no_improvement_counter <- 0
previous_best_info <- list(scores = best_info_env$best_scores, paths = best_info_env$best_rule_paths)
while (total_iterations < max_iterations && no_improvement_counter < no_improvement_threshold) {
external_temperature <- cooling_schedule(total_iterations, max_iterations, max_temperature, min_temperature)
iteration_time <- system.time({
result <- recursive_build_logic_tree(data, outcome, columns, max_operators, current_operators = 1, parent_score = 0, previous_rule = NULL, previous_rule_name = "", best_info_env = best_info_env, external_temperature, two_way_logic_roots, beam_width, max_trees)
})
total_iterations <- total_iterations + 1
iteration_counter <- iteration_counter + 1
# Check for improvement
if (!identical(previous_best_info$scores, best_info_env$best_scores)) {
no_improvement_counter <- 0
previous_best_info$scores <- best_info_env$best_scores
} else {
no_improvement_counter <- no_improvement_counter + 1
}
}
return(list(
best_scores = best_info_env$best_scores,
best_rule_paths = best_info_env$best_rule_paths
))
}
# Export objects to the cluster
clusterExport(cl, c("data", "outcome", "columns", "max_trees", "max_operators",
"max_temperature", "min_temperature", "iterations_per_core",
"no_improvement_threshold", "two_way_logic_roots", "beam_width" ), envir = environment())
results <- parLapply(cl, 1:num_cores, function(x) {
run_single_iteration(data, outcome, columns, max_operators, max_trees = max_trees, max_temperature, min_temperature, max_iterations = iterations_per_core, two_way_logic_roots, beam_width, max_trees)
})
install()
install()
